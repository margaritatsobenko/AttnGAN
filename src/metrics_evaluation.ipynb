{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf704d0",
   "metadata": {
    "cellId": "rryyhb4t1zkp771ivbb1"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8dcc03",
   "metadata": {
    "cellId": "x86z3u73whe6na31pbe0tb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886515e6",
   "metadata": {
    "cellId": "chhr46uou6ppluijvio8la"
   },
   "outputs": [],
   "source": [
    "current_cwd = os.getcwd()\n",
    "src_path = '/'.join(current_cwd.split('/')[:-1])\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563f3cec",
   "metadata": {
    "cellId": "z3yt4m0r0noxuq1cks819b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import linalg\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.stats import entropy\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.generator.model import Generator\n",
    "from src.encoders.text_encoder import RNNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79c7aaf",
   "metadata": {
    "cellId": "7xpb1bz7kj6p30rx0amxp"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7fe53",
   "metadata": {
    "cellId": "0m05l99ya2md3pyjlbyx6tp"
   },
   "source": [
    "# Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9acd84e3",
   "metadata": {
    "cellId": "7uhcd37kkl3rsz3jvbqe5h"
   },
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = f'cuda:{0}' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.6.0', 'inception_v3', pretrained=True).to(self.device)\n",
    "        print(self.model.fc)\n",
    "        self.linear = self.model.fc\n",
    "        self.model.fc, self.model.dropout = [nn.Sequential()] * 2\n",
    "      \n",
    "    @torch.no_grad()\n",
    "    def get_last_layer(self, x):\n",
    "        x = F.interpolate(x, size=300, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af0c784",
   "metadata": {
    "cellId": "qzco1t75tjkzjgyiov9ijm"
   },
   "outputs": [],
   "source": [
    "classifier = InceptionV3().to(device)\n",
    "classifier = classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c43295",
   "metadata": {
    "cellId": "ca0kepfh30wy0z4srjs9l"
   },
   "source": [
    "# Dataset + DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fa4af2",
   "metadata": {
    "cellId": "p1yhwcrpbgnfg3w69bbe8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.objects.dataset import AttnGANDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6137bb8",
   "metadata": {
    "cellId": "8gam5n76mo261kwlqe5kdr"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "split_dir, bshuffle = 'test', True\n",
    "image_size = 64 * (2 ** (3 - 1))\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Scale(int(image_size * 76 / 64)),\n",
    "    transforms.RandomCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])\n",
    "\n",
    "data_dir = \"../data\"\n",
    "dataset = AttnGANDataset(data_dir, split_dir, image_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, drop_last=True, shuffle=bshuffle)\n",
    "n_words = test_loader.dataset.n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3514442",
   "metadata": {
    "cellId": "k3wc9j5o9abglnlfypvxb6"
   },
   "source": [
    "# Generator + Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24f25d2",
   "metadata": {
    "cellId": "ajrxgeoiv3izsi3g129fs"
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "generator.load_state_dict(torch.load(\"../gen_weights_70/gen_weights_epoch_9.pth\", map_location=device))\n",
    "generator = generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5741ec0",
   "metadata": {
    "cellId": "io7gl5aajmfzal1q9sz09"
   },
   "outputs": [],
   "source": [
    "text_encoder = RNNEncoder.load(\"../encoder_weights/text_encoder200.pth\", n_words)\n",
    "text_encoder.to(device)\n",
    "\n",
    "for p in text_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "text_encoder = text_encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62a632",
   "metadata": {
    "cellId": "g7g8eif0xpsk9kydth186d"
   },
   "source": [
    "# FID calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0128c595",
   "metadata": {
    "cellId": "ts4553yhpqqm67xjlp0n"
   },
   "outputs": [],
   "source": [
    "def calculate_fid(repr1, repr2):\n",
    "    # shape of reprs: (-1, embed_dim)\n",
    "    \n",
    "    # shape of mus: (embed_dim, )\n",
    "    mu_r, mu_g = np.mean(repr1, axis=0), np.mean(repr2, axis=0)\n",
    "    # rowvar=False:\n",
    "    #     each column represents a variable, while the rows contain observations\n",
    "    # shape of sigmas: (embed_dim, embed_dim)\n",
    "    sigma_r, sigma_g = np.cov(repr1, rowvar=False), np.cov(repr2, rowvar=False)\n",
    "    \n",
    "    diff = mu_r - mu_g\n",
    "    diff_square_norm = diff.dot(diff)\n",
    "    \n",
    "    product = sigma_r.dot(sigma_g)\n",
    "    sqrt_product, _ = sqrtm(product, disp=False)\n",
    "    \n",
    "    # np.isfinite:\n",
    "    #     Test element-wise for finiteness \n",
    "    #     (not infinity and not Not a Number)\n",
    "    if not np.isfinite(sqrt_product).all():\n",
    "        eye_matrix = np.eye(sigma_r.shape[0]) * 1e-8\n",
    "        sqrt_product = linalg.sqrtm((sigma_r + eye_matrix).dot(sigma_g + eye_matrix))\n",
    "    \n",
    "    # np.iscomplexobj:\n",
    "    #     Check for a complex type or an array of complex numbers.\n",
    "    #     The return value, True if x is of a complex type\n",
    "    #     or has at least one complex element.\n",
    "    if np.iscomplexobj(sqrt_product):\n",
    "        sqrt_product = sqrt_product.real\n",
    "\n",
    "    fid = diff_square_norm + np.trace(sigma_r + sigma_g - 2 * sqrt_product)\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d039ab0",
   "metadata": {
    "cellId": "wthh7gkoxacbiqrkwp631"
   },
   "outputs": [],
   "source": [
    "from src.objects.utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad361b4",
   "metadata": {
    "cellId": "xnpm1lp2ttpbxegemjexyd"
   },
   "outputs": [],
   "source": [
    "def build_representations():\n",
    "    real_reprs = np.zeros((len(test_loader) * batch_size, 2048))\n",
    "    fake_reprs = np.zeros((len(test_loader) * batch_size, 2048))\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(test_loader, desc=\"Build representations\")):\n",
    "        images, captions, captions_len, cls_ids, file_names = prepare_data(batch, device)\n",
    "        \n",
    "        word_embeds, sentence_embeds = text_encoder(captions, captions_len)\n",
    "    \n",
    "        mask = (captions == 0)\n",
    "        num_words = word_embeds.size(2)\n",
    "\n",
    "        if mask.size(1) > num_words:\n",
    "            mask = mask[:, :num_words]\n",
    "\n",
    "        noise = torch.randn(sentence_embeds.shape[0], 100, device=device)\n",
    "        fake_images, _, mu, log_var = generator(noise, sentence_embeds, word_embeds, mask)\n",
    "        \n",
    "        fake_images = fake_images[2]\n",
    "\n",
    "        clf_out_real = classifier.get_last_layer(images[0])\n",
    "        clf_out_fake = classifier.get_last_layer(fake_images)\n",
    "\n",
    "\n",
    "        real_reprs[i * batch_size: (i + 1) * batch_size] = clf_out_real.cpu()\n",
    "        fake_reprs[i * batch_size: (i + 1) * batch_size] = clf_out_fake.cpu()\n",
    "            \n",
    "    return real_reprs, fake_reprs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf30187",
   "metadata": {
    "cellId": "537cpwjqe7immvd6p74x5o"
   },
   "source": [
    "## Build representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376c4fa9",
   "metadata": {
    "cellId": "fz838gn59h455j905nxb0y"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6c2dad1",
   "metadata": {
    "cellId": "9idrstespvapj3us970il8"
   },
   "outputs": [],
   "source": [
    "real_values, fake_values = build_representations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bffcde",
   "metadata": {
    "cellId": "7ub6gv0alc8er9fgemv794"
   },
   "source": [
    "## FID value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c2ec59f",
   "metadata": {
    "cellId": "654ados6gxta8pkiehuvle"
   },
   "outputs": [],
   "source": [
    "fid_value = calculate_fid(real_values, fake_values)\n",
    "print(f\"FID value = {fid_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749bf164",
   "metadata": {
    "cellId": "2jdca8mppd3p6vh5o44oo"
   },
   "source": [
    "# Inception score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346db53a",
   "metadata": {
    "cellId": "w09333ma9kgq0njplvkc"
   },
   "outputs": [],
   "source": [
    "def inception_score(reprs, batch_size):\n",
    "    def get_pred(x):\n",
    "        x = classifier.linear(torch.tensor(x, dtype=torch.float, device=device))\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    preds = np.zeros((reprs.shape[0], 1000))\n",
    "    \n",
    "    splits = 0\n",
    "    for i in range(0, len(preds), batch_size):\n",
    "        z = get_pred(reprs[i:i + batch_size])\n",
    "        preds[i:i + batch_size] = z\n",
    "        splits += 1\n",
    "    \n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * batch_size: (k+1) * batch_size, :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "            \n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "228d6448",
   "metadata": {
    "cellId": "hgy30r3mo7m6q9fao9riyn"
   },
   "outputs": [],
   "source": [
    "inception_score(fake_values, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "notebookId": "3f84fd5f-5e73-478b-a98f-1662e67c8f6e",
  "notebookPath": "src/metrics_evaluation (1).ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
