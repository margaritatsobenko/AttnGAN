{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b4fec7",
   "metadata": {
    "cellId": "hjr9vfszx4oh76p8vpbdy7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d24c16",
   "metadata": {
    "cellId": "ufuhhdhlsqgwyrgdezrroj"
   },
   "outputs": [],
   "source": [
    "current_cwd = os.getcwd()\n",
    "src_path = '/'.join(current_cwd.split('/')[:-1])\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fced7f1c",
   "metadata": {
    "cellId": "bog612305t5942kyaxl5r8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.generator.model import Generator\n",
    "from src.encoders.text_encoder import RNNEncoder\n",
    "from src.objects.dataset import AttnGANDataset\n",
    "from src.objects.utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbbffa3",
   "metadata": {
    "cellId": "vtmhiyb8rsp1xtwp2pcbk5"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54cec354",
   "metadata": {
    "cellId": "1noiiu2pwynkaksv8mokug"
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "generator.load_state_dict(torch.load(\"../gen_weights_70/gen_weights_epoch_69.pth\", map_location=device))\n",
    "generator = generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e0c198",
   "metadata": {
    "cellId": "rajjgh6pulgw90bieqzuiq"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "split_dir, bshuffle = 'test', True\n",
    "image_size = 64 * (2 ** (3 - 1))\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Scale(int(image_size * 76 / 64)),\n",
    "    transforms.RandomCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])\n",
    "\n",
    "data_dir = \"../data\"\n",
    "dataset = AttnGANDataset(data_dir, split_dir, image_transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True, shuffle=bshuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f47073",
   "metadata": {
    "cellId": "0q5y2nln95ugnnxip5yru3"
   },
   "outputs": [],
   "source": [
    "n_words = dataloader.dataset.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076e66f6",
   "metadata": {
    "cellId": "f7llri7wsygvy8g5lfdr1"
   },
   "outputs": [],
   "source": [
    "text_encoder = RNNEncoder.load(\"../encoder_weights/text_encoder200.pth\", n_words)\n",
    "text_encoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e33c13",
   "metadata": {
    "cellId": "lz8d24x8r82wp9ntkfuzj"
   },
   "source": [
    "# Own birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47c67fd",
   "metadata": {
    "cellId": "ld3e05h61dq9ttvyqtgevm"
   },
   "outputs": [],
   "source": [
    "def save_image(image: np.ndarray, save_dir: str, file_name: str):\n",
    "    # [-1, 1] --> [0, 255]\n",
    "    image = (image + 1.0) * 127.5\n",
    "    image = image.astype(np.uint8)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = Image.fromarray(image)\n",
    "    fullpath = os.path.join(save_dir, f\"{file_name.replace('/', '_')}.png\")\n",
    "    image.save(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be27d69b",
   "metadata": {
    "cellId": "ouhkvaf5abjsbmbpr9bh"
   },
   "outputs": [],
   "source": [
    "def gen_own_bird(word_caption, name):\n",
    "    codes = [dataset.word2code[w] for w in word_caption.lower().split()]\n",
    "    \n",
    "    caption = np.array(codes)\n",
    "    pad_caption = np.zeros((18, 1), dtype='int64')\n",
    "\n",
    "    if len(caption) <= 18:\n",
    "        pad_caption[:len(caption), 0] = caption\n",
    "        len_ = len(caption)\n",
    "    else:\n",
    "        indices = list(np.arange(len(caption)))\n",
    "        np.random.shuffle(indices)\n",
    "        pad_caption[:, 0] = caption[np.sort(indices[:18])]\n",
    "        len_ = 18\n",
    "\n",
    "    captions = torch.tensor(pad_caption).reshape(1, -1)\n",
    "    captions_len = torch.tensor([len_])\n",
    "    word_embeds, sentence_embeds = text_encoder(captions, captions_len)\n",
    "    \n",
    "    mask = (captions == 0)\n",
    "    num_words = word_embeds.size(2)\n",
    "\n",
    "    if mask.size(1) > num_words:\n",
    "        mask = mask[:, :num_words]\n",
    "        \n",
    "    batch_size = sentence_embeds.shape[0]\n",
    "        \n",
    "    noise = torch.randn(batch_size, 100, device=device)\n",
    "    fake_images, _, mu, log_var = generator(noise, sentence_embeds, word_embeds, mask)\n",
    "    \n",
    "    save_image(fake_images[2][0].data.cpu().numpy(), \"../gen_images\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd7cc95",
   "metadata": {
    "cellId": "xza6h2cz99scpb731t2le"
   },
   "outputs": [],
   "source": [
    "caption = \"Small brown chicken with red crown and yellow wings\"\n",
    "gen_own_bird(caption, caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b438f6",
   "metadata": {
    "cellId": "axigzpdwu5w1d15libgjvq"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e416adee",
   "metadata": {
    "cellId": "wfd8i4zd6yrgrceb73t26k"
   },
   "outputs": [],
   "source": [
    "images, captions, captions_len, _, file_names = prepare_data(batch, device)\n",
    "word_embeds, sentence_embeds = text_encoder(captions, captions_len)\n",
    "\n",
    "mask = (captions == 0)\n",
    "num_words = word_embeds.size(2)\n",
    "\n",
    "if mask.size(1) > num_words:\n",
    "    mask = mask[:, :num_words]\n",
    "\n",
    "batch_size = sentence_embeds.shape[0]\n",
    "\n",
    "noise = torch.randn(batch_size, 100, device=device)\n",
    "fake_images, _, mu, log_var = generator(noise, sentence_embeds, word_embeds, mask)\n",
    "\n",
    "vutils.save_image(fake_images[2].data, \"../gen_images_70/birds.png\", normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "notebookId": "a58bed65-c5a3-422e-b529-2ddab3320e48",
  "notebookPath": "src/eval_example.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
